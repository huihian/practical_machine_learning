---
title: Coursera Practical Machine Learning Course Project
output: html_document
---

##Objective
 Fitness devices eg. Fitbit are becoming more common and the objective of this project is to predict the manner in which prople do the exercise using certain training data.

##Load all libraries neccessary for this project

```{r, results="hide", warning=FALSE, message=FALSE}
library(caret)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
library(randomForest)
library(e1071)

```

##Data

The training data for this project is available here: 
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv 

The test data for this project is available here: 
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

A copy of the above data is downloaded into my working directory and loaded.

```{r}
training <- read.csv("pml-training.csv", na.strings=c("NA","#DIV/0!",""))
testing <- read.csv("pml-testing.csv", na.strings=c("NA","#DIV/0!",""))
```

Before building the model, the training data set is partitioned into 2 datasets; 60% for training and 40% for validation. 

```{r}
set.seed (12345)#ensure reproducibility

inTrain <- createDataPartition(y=training$classe, p=0.6, list=FALSE)
myTraining <- training[inTrain, ];myTesting <- training[-inTrain, ]
dim(myTraining); dim(myTesting)
```

##Data Cleansing and Transformation

Before building the model, there is a need to perform some data transformation on our datasets. We will start with myTraining data first before doing the same for the others. 

1) Clean and remove Near zero Variance (NZV) variables

```{r}
#To identify NZV Variables
NZV <- nearZeroVar(myTraining, saveMetrics=TRUE)

#Create subset of myTraining data without NZV variables 

NZVvars <- names(myTraining) %in% c("new_window", "kurtosis_roll_belt", "kurtosis_picth_belt",
"kurtosis_yaw_belt", "skewness_roll_belt", "skewness_roll_belt.1", "skewness_yaw_belt",
"max_yaw_belt", "min_yaw_belt", "amplitude_yaw_belt", "avg_roll_arm", "stddev_roll_arm",
"var_roll_arm", "avg_pitch_arm", "stddev_pitch_arm", "var_pitch_arm", "avg_yaw_arm",
"stddev_yaw_arm", "var_yaw_arm", "kurtosis_roll_arm", "kurtosis_picth_arm",
"kurtosis_yaw_arm", "skewness_roll_arm", "skewness_pitch_arm", "skewness_yaw_arm",
"max_roll_arm", "min_roll_arm", "min_pitch_arm", "amplitude_roll_arm", "amplitude_pitch_arm",
"kurtosis_roll_dumbbell", "kurtosis_picth_dumbbell", "kurtosis_yaw_dumbbell", "skewness_roll_dumbbell",
"skewness_pitch_dumbbell", "skewness_yaw_dumbbell", "max_yaw_dumbbell", "min_yaw_dumbbell",
"amplitude_yaw_dumbbell", "kurtosis_roll_forearm", "kurtosis_picth_forearm", "kurtosis_yaw_forearm",
"skewness_roll_forearm", "skewness_pitch_forearm", "skewness_yaw_forearm", "max_roll_forearm",
"max_yaw_forearm", "min_roll_forearm", "min_yaw_forearm", "amplitude_roll_forearm",
"amplitude_yaw_forearm", "avg_roll_forearm", "stddev_roll_forearm", "var_roll_forearm",
"avg_pitch_forearm", "stddev_pitch_forearm", "var_pitch_forearm", "avg_yaw_forearm",
"stddev_yaw_forearm", "var_yaw_forearm")
myTraining <- myTraining[!NZVvars]
```

2) Remove IDs

```{r}
myTraining <- myTraining[c(-1)]
```

3) Remove Variables with too many missing values. 

```{r}
trainingV3 <- myTraining 
for(i in 1:length(myTraining)) { 
        if( sum( is.na( myTraining[, i] ) ) /nrow(myTraining) >= .6 ) { 
        for(j in 1:length(trainingV3)) {
            if( length( grep(names(myTraining[i]), names(trainingV3)[j]) ) ==1)  { 
                trainingV3 <- trainingV3[ , -j] 
            }   
        } 
    }
}
myTraining <- trainingV3
```

Replicate the above on the other 2 datasets: Testing and mytesting

```{r}
clean1 <- colnames(myTraining)
clean2 <- colnames(myTraining[, -58]) 
myTesting <- myTesting[clean1]
testing <- testing[clean2]
```

Lastly, to ensure that we can use the RandomForest Algorithm on the Test data set (testing), we need to coerce the data into the same type.

```{r}
for (i in 1:length(testing) ) {
        for(j in 1:length(myTraining)) {
        if( length( grep(names(myTraining[i]), names(testing)[j]) ) ==1)  {
            class(testing[j]) <- class(myTraining[i])
        }      
    }      
}

testing <- rbind(myTraining[2, -58] , testing) 
testing <- testing[-1,]
```

##Decision Tree

Now we use train the model using Decision Tree with the training data set (myTraining)

```{r}
modFitA1 <- rpart(classe ~ ., data=myTraining, method="class")

#visualise tree
fancyRpartPlot(modFitA1)
```

After the model has been built, we need to validate the results using the validation dataset (myTesting)
```{r}
predictionsA1 <- predict(modFitA1, myTesting, type = "class")
confusionMatrix(predictionsA1, myTesting$classe)
```

##Random Forest 

A second model using Random Forest is used on the training data set (myTraining)

```{r}
modFitB1 <- randomForest(classe ~. , data=myTraining)
```

Similarly, after the model has been built, we need to validate the results using the validation dataset (myTesting)

```{r}
predictionsB1 <- predict(modFitB1, myTesting, type = "class")
confusionMatrix(predictionsB1, myTesting$classe)
```

The accuracy of the random forest is much better and gave better results. 

##Predict the testing data using the better model

From the above, it can be seen that Random Forest gave better results and hence it was used. 

```{r}
predictionsB2 <- predict(modFitB1, testing, type = "class")

#use the codes below for predicting the 20 sample data from the course

pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

pml_write_files(predictionsB2)
```


